# ============================================
# Docker Compose - Local Development
# Iris ML API v4 - Enterprise Template
# ============================================
#
# Usage:
#   docker-compose up -d          # Start all services
#   docker-compose logs -f        # View logs
#   docker-compose down           # Stop all services
#   docker-compose build          # Rebuild images
#
# Services:
#   - api-gateway:       http://localhost:8080
#   - inference-service: http://localhost:5000
#

version: "3.8"

services:
  # Python Inference Service (ML Model)
  inference-service:
    build:
      context: ./apps/inference-service
      dockerfile: Dockerfile
    container_name: iris-inference-service
    ports:
      - "5000:5000"
    environment:
      - MODEL_PATH=/app/models/model.pkl
      - MODEL_VERSION=1.0.0-dev
      - API_KEY=${API_KEY:-}
      - PYTHONUNBUFFERED=1
    volumes:
      - ./ml/models:/app/models:ro
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:5000/health/live', timeout=2)"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    restart: unless-stopped
    networks:
      - iris-network

  # Java API Gateway (Spring Boot)
  api-gateway:
    build:
      context: ./apps/api-gateway
      dockerfile: Dockerfile
    container_name: iris-api-gateway
    ports:
      - "8080:8080"
    environment:
      - INFERENCE_SERVICE_URL=http://inference-service:5000
      - MODEL_VERSION=1.0.0-dev
      - API_KEY=${API_KEY:-}
      - SPRING_PROFILES_ACTIVE=docker
    depends_on:
      inference-service:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/health/live"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - iris-network

networks:
  iris-network:
    driver: bridge
    name: iris-ml-network

# Optional volumes for persistent data
volumes:
  models:
    driver: local
